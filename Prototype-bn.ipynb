{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TKU\\anaconda3\\envs\\UMTRA2\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import tensorflow.keras.backend as keras_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 90\n",
    "shots = 2\n",
    "classes = 5\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "batch_size = 256\n",
    "n_way =5\n",
    "k_shot =5\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    # 將圖像調整為適合模型的大小，例如 32x32\n",
    "    image = tf.image.resize(image, (28, 28))\n",
    "    # 標準化圖像到 [0, 1]\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    image = tf.cast(image, tf.float64) / 255.0\n",
    "    return image, label\n",
    "\n",
    "def convert_to_rgb(x, y):\n",
    "    # 假設 x 是影像，y 是標籤\n",
    "    x_rgb = tf.image.grayscale_to_rgb(x)\n",
    "    return x_rgb, y\n",
    "\n",
    "def show_images(dataset, num_images=5):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, (image, label) in enumerate(dataset.take(1)):  # 取第一批資料\n",
    "        for j in range(num_images):\n",
    "            ax = plt.subplot(1, num_images, j + 1)\n",
    "            plt.imshow(image[j])  # 顯示第 j 張圖片\n",
    "            plt.title(f\"Label: {label[j].numpy()}\")\n",
    "            plt.axis(\"off\")\n",
    "    plt.show()\n",
    "def to64(image, label):\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    image = tf.cast(image, tf.float64)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fewshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found a different version 3.0.0 of dataset omniglot in data_dir C:\\Users\\TKU\\tensorflow_datasets. Using currently defined version 1.0.0.\n",
      "WARNING:absl:Found a different version 3.0.0 of dataset omniglot in data_dir C:\\Users\\TKU\\tensorflow_datasets. Using currently defined version 1.0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963]\n",
      "[964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963]\n",
      "17352\n",
      "1928\n",
      "13180\n",
      "17352\n",
      "1928\n",
      "13180\n"
     ]
    }
   ],
   "source": [
    "train_ds , info= tfds.load(\"omniglot\", split='train', as_supervised=True, shuffle_files=False,with_info=True)\n",
    "train_data = []\n",
    "test_data = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "data={}\n",
    "tdata={}\n",
    "clk = 0\n",
    "def extraction(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float64)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.resize(image, [28, 28])\n",
    "    return image, label\n",
    "        \n",
    "for image, label in train_ds.map(extraction):\n",
    "    image = image.numpy()\n",
    "    label = str(label.numpy())\n",
    "    if label not in data:\n",
    "        data[label] = []\n",
    "    data[label].append(image)\n",
    "    train_labels = list(data.keys())\n",
    "ds= tfds.load(\"omniglot\", split=\"test\", as_supervised=True, shuffle_files=False)\n",
    "\n",
    "for image, label in ds.map(extraction):\n",
    "    image = image.numpy()\n",
    "    label = str(label.numpy())\n",
    "    if label not in tdata:\n",
    "        tdata[label] = []\n",
    "    tdata[label].append(image)\n",
    "    test_labels = list(tdata.keys())\n",
    "    \n",
    "test_labels = set(test_labels) \n",
    "a = list(map(int,test_labels))\n",
    "a.sort()\n",
    "print(a)\n",
    "\n",
    "train_labels = set(train_labels) \n",
    "b = list(map(int,train_labels))\n",
    "b.sort()\n",
    "print(b)\n",
    "test_labels = set(test_labels) \n",
    "a = list(map(int,test_labels))\n",
    "a.sort()\n",
    "print(a)\n",
    "\n",
    "train_labels = set(train_labels) \n",
    "b = list(map(int,train_labels))\n",
    "b.sort()\n",
    "print(b)\n",
    "\n",
    "x_omni_train = []\n",
    "x_omni_val = []\n",
    "x_omni_test = []\n",
    "y_omni_train = []\n",
    "y_omni_val = []\n",
    "y_omni_test = []\n",
    "\n",
    "for i in range(964):\n",
    "    x_omni_train.extend(data[f\"{i}\"][:18])\n",
    "    x_omni_val.extend(data[f\"{i}\"][-2:])\n",
    "    \n",
    "for i in range(964,1623,1):\n",
    "    x_omni_test.extend(tdata[f\"{i}\"][:20])\n",
    "    \n",
    "for i in range(964):\n",
    "    for j in range(18):\n",
    "        y_omni_train.append(i)\n",
    "        \n",
    "for i in range(964):\n",
    "    for j in range(2):\n",
    "        y_omni_val.append(i)\n",
    "        \n",
    "for i in range(964,1623,1):\n",
    "    for j in range(20):\n",
    "        y_omni_test.append(i)\n",
    "x_omni_train = np.array(x_omni_train)\n",
    "x_omni_val = np.array(x_omni_val)\n",
    "x_omni_test = np.array(x_omni_test)\n",
    "y_omni_train = np.array(y_omni_train)\n",
    "y_omni_val = np.array(y_omni_val)\n",
    "y_omni_test = np.array(y_omni_test)\n",
    "\n",
    "print(len(x_omni_train))\n",
    "print(len(x_omni_val))\n",
    "print(len(x_omni_test))\n",
    "print(len(y_omni_train))\n",
    "print(len(y_omni_val))\n",
    "print(len(y_omni_test))\n",
    "\n",
    "omni_train = tf.data.Dataset.from_tensor_slices((x_omni_train, y_omni_train)).shuffle(len(x_omni_train)).batch(batch_size).map(to64)\n",
    "omni_val = tf.data.Dataset.from_tensor_slices((x_omni_val, y_omni_val)).shuffle(len(x_omni_val)).batch(batch_size).map(to64)\n",
    "omni_test = tf.data.Dataset.from_tensor_slices((x_omni_test, y_omni_test)).shuffle(len(x_omni_test)).batch(batch_size).map(to64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.bn1   = tf.keras.layers.BatchNormalization()\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.bn2   = tf.keras.layers.BatchNormalization()\n",
    "        self.relu2 = tf.keras.layers.ReLU()\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.bn3   = tf.keras.layers.BatchNormalization()\n",
    "        self.relu3 = tf.keras.layers.ReLU()\n",
    "        self.pool3 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.bn4   = tf.keras.layers.BatchNormalization()\n",
    "        self.relu4 = tf.keras.layers.ReLU()\n",
    "        self.pool4 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(964, activation=\"softmax\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "                          bias_regularizer=tf.keras.regularizers.L2(1e-4),\n",
    "                          activity_regularizer=tf.keras.regularizers.L2(1e-5))\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def call(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        output = self.dense(x)\n",
    "        return output\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.build(input_shape=(None, 28, 28, 1))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Step 0, Loss: 8.3003\n",
      "Step 35, Loss: 6.8500\n",
      "Training acc over epoch: 0.0013\n",
      "Validation acc: 0.0010\n",
      "Validation Loss: 0.0010\n",
      "Saved best model checkpoint at epoch 0\n",
      "\n",
      "Start of epoch 1\n",
      "Step 0, Loss: 6.8561\n",
      "Step 35, Loss: 6.8354\n",
      "Training acc over epoch: 0.0028\n",
      "Validation acc: 0.0005\n",
      "Validation Loss: 0.0005\n",
      "\n",
      "Start of epoch 2\n",
      "Step 0, Loss: 6.7589\n",
      "Step 35, Loss: 6.7969\n",
      "Training acc over epoch: 0.0050\n",
      "Validation acc: 0.0010\n",
      "Validation Loss: 0.0010\n",
      "\n",
      "Start of epoch 3\n",
      "Step 0, Loss: 6.6987\n",
      "Step 35, Loss: 6.6966\n",
      "Training acc over epoch: 0.0078\n",
      "Validation acc: 0.0005\n",
      "Validation Loss: 0.0005\n",
      "\n",
      "Start of epoch 4\n",
      "Step 0, Loss: 6.6467\n",
      "Step 35, Loss: 6.5720\n",
      "Training acc over epoch: 0.0134\n",
      "Validation acc: 0.0000\n",
      "Validation Loss: 0.0000\n",
      "\n",
      "Start of epoch 5\n",
      "Step 0, Loss: 6.5143\n",
      "Step 35, Loss: 6.4040\n",
      "Training acc over epoch: 0.0212\n",
      "Validation acc: 0.0031\n",
      "Validation Loss: 0.0031\n",
      "Saved best model checkpoint at epoch 5\n",
      "\n",
      "Start of epoch 6\n",
      "Step 0, Loss: 6.3057\n",
      "Step 35, Loss: 6.2820\n",
      "Training acc over epoch: 0.0302\n",
      "Validation acc: 0.0119\n",
      "Validation Loss: 0.0119\n",
      "Saved best model checkpoint at epoch 6\n",
      "\n",
      "Start of epoch 7\n",
      "Step 0, Loss: 6.0837\n",
      "Step 35, Loss: 6.2126\n",
      "Training acc over epoch: 0.0447\n",
      "Validation acc: 0.0213\n",
      "Validation Loss: 0.0213\n",
      "Saved best model checkpoint at epoch 7\n",
      "\n",
      "Start of epoch 8\n",
      "Step 0, Loss: 5.9487\n",
      "Step 35, Loss: 5.7427\n",
      "Training acc over epoch: 0.0637\n",
      "Validation acc: 0.0337\n",
      "Validation Loss: 0.0337\n",
      "Saved best model checkpoint at epoch 8\n",
      "\n",
      "Start of epoch 9\n",
      "Step 0, Loss: 5.7540\n",
      "Step 35, Loss: 5.5320\n",
      "Training acc over epoch: 0.0892\n",
      "Validation acc: 0.0410\n",
      "Validation Loss: 0.0410\n",
      "Saved best model checkpoint at epoch 9\n",
      "\n",
      "Start of epoch 10\n",
      "Step 0, Loss: 5.1663\n",
      "Step 35, Loss: 5.1457\n",
      "Training acc over epoch: 0.1283\n",
      "Validation acc: 0.0545\n",
      "Validation Loss: 0.0545\n",
      "Saved best model checkpoint at epoch 10\n",
      "\n",
      "Start of epoch 11\n",
      "Step 0, Loss: 4.7742\n",
      "Step 35, Loss: 4.7082\n",
      "Training acc over epoch: 0.1739\n",
      "Validation acc: 0.0550\n",
      "Validation Loss: 0.0550\n",
      "Saved best model checkpoint at epoch 11\n",
      "\n",
      "Start of epoch 12\n",
      "Step 0, Loss: 4.3291\n",
      "Step 35, Loss: 4.1751\n",
      "Training acc over epoch: 0.2327\n",
      "Validation acc: 0.0622\n",
      "Validation Loss: 0.0622\n",
      "Saved best model checkpoint at epoch 12\n",
      "\n",
      "Start of epoch 13\n",
      "Step 0, Loss: 3.8697\n",
      "Step 35, Loss: 3.9222\n",
      "Training acc over epoch: 0.2996\n",
      "Validation acc: 0.1079\n",
      "Validation Loss: 0.1079\n",
      "Saved best model checkpoint at epoch 13\n",
      "\n",
      "Start of epoch 14\n",
      "Step 0, Loss: 3.1978\n",
      "Step 35, Loss: 3.4532\n",
      "Training acc over epoch: 0.3718\n",
      "Validation acc: 0.0934\n",
      "Validation Loss: 0.0934\n",
      "\n",
      "Start of epoch 15\n",
      "Step 0, Loss: 2.9105\n",
      "Step 35, Loss: 2.8475\n",
      "Training acc over epoch: 0.4385\n",
      "Validation acc: 0.1343\n",
      "Validation Loss: 0.1343\n",
      "Saved best model checkpoint at epoch 15\n",
      "\n",
      "Start of epoch 16\n",
      "Step 0, Loss: 2.4312\n",
      "Step 35, Loss: 2.4494\n",
      "Training acc over epoch: 0.5022\n",
      "Validation acc: 0.1561\n",
      "Validation Loss: 0.1561\n",
      "Saved best model checkpoint at epoch 16\n",
      "\n",
      "Start of epoch 17\n",
      "Step 0, Loss: 2.0806\n",
      "Step 35, Loss: 1.8532\n",
      "Training acc over epoch: 0.5757\n",
      "Validation acc: 0.1307\n",
      "Validation Loss: 0.1307\n",
      "\n",
      "Start of epoch 18\n",
      "Step 0, Loss: 1.7170\n",
      "Step 35, Loss: 1.9660\n",
      "Training acc over epoch: 0.6356\n",
      "Validation acc: 0.1670\n",
      "Validation Loss: 0.1670\n",
      "Saved best model checkpoint at epoch 18\n",
      "\n",
      "Start of epoch 19\n",
      "Step 0, Loss: 1.3362\n",
      "Step 35, Loss: 1.5899\n",
      "Training acc over epoch: 0.6872\n",
      "Validation acc: 0.1219\n",
      "Validation Loss: 0.1219\n",
      "\n",
      "Start of epoch 20\n",
      "Step 0, Loss: 1.3367\n",
      "Step 35, Loss: 1.2494\n",
      "Training acc over epoch: 0.7400\n",
      "Validation acc: 0.2796\n",
      "Validation Loss: 0.2796\n",
      "Saved best model checkpoint at epoch 20\n",
      "\n",
      "Start of epoch 21\n",
      "Step 0, Loss: 0.8774\n",
      "Step 35, Loss: 0.9550\n",
      "Training acc over epoch: 0.7805\n",
      "Validation acc: 0.2739\n",
      "Validation Loss: 0.2739\n",
      "\n",
      "Start of epoch 22\n",
      "Step 0, Loss: 0.8434\n",
      "Step 35, Loss: 0.9247\n",
      "Training acc over epoch: 0.8264\n",
      "Validation acc: 0.3045\n",
      "Validation Loss: 0.3045\n",
      "Saved best model checkpoint at epoch 22\n",
      "\n",
      "Start of epoch 23\n",
      "Step 0, Loss: 0.7437\n",
      "Step 35, Loss: 0.5791\n",
      "Training acc over epoch: 0.8557\n",
      "Validation acc: 0.3454\n",
      "Validation Loss: 0.3454\n",
      "Saved best model checkpoint at epoch 23\n",
      "\n",
      "Start of epoch 24\n",
      "Step 0, Loss: 0.6006\n",
      "Step 35, Loss: 0.6508\n",
      "Training acc over epoch: 0.8862\n",
      "Validation acc: 0.3548\n",
      "Validation Loss: 0.3548\n",
      "Saved best model checkpoint at epoch 24\n",
      "\n",
      "Start of epoch 25\n",
      "Step 0, Loss: 0.4763\n",
      "Step 35, Loss: 0.5527\n",
      "Training acc over epoch: 0.9123\n",
      "Validation acc: 0.4258\n",
      "Validation Loss: 0.4258\n",
      "Saved best model checkpoint at epoch 25\n",
      "\n",
      "Start of epoch 26\n",
      "Step 0, Loss: 0.3779\n",
      "Step 35, Loss: 0.4968\n",
      "Training acc over epoch: 0.9325\n",
      "Validation acc: 0.3807\n",
      "Validation Loss: 0.3807\n",
      "\n",
      "Start of epoch 27\n",
      "Step 0, Loss: 0.3838\n",
      "Step 35, Loss: 0.3760\n",
      "Training acc over epoch: 0.9452\n",
      "Validation acc: 0.4502\n",
      "Validation Loss: 0.4502\n",
      "Saved best model checkpoint at epoch 27\n",
      "\n",
      "Start of epoch 28\n",
      "Step 0, Loss: 0.2911\n",
      "Step 35, Loss: 0.3018\n",
      "Training acc over epoch: 0.9614\n",
      "Validation acc: 0.4035\n",
      "Validation Loss: 0.4035\n",
      "\n",
      "Start of epoch 29\n",
      "Step 0, Loss: 0.2354\n",
      "Step 35, Loss: 0.2466\n",
      "Training acc over epoch: 0.9731\n",
      "Validation acc: 0.4040\n",
      "Validation Loss: 0.4040\n",
      "\n",
      "Start of epoch 30\n",
      "Step 0, Loss: 0.2174\n",
      "Step 35, Loss: 0.2329\n",
      "Training acc over epoch: 0.9808\n",
      "Validation acc: 0.4409\n",
      "Validation Loss: 0.4409\n",
      "\n",
      "Start of epoch 31\n",
      "Step 0, Loss: 0.1696\n",
      "Step 35, Loss: 0.1650\n",
      "Training acc over epoch: 0.9862\n",
      "Validation acc: 0.4694\n",
      "Validation Loss: 0.4694\n",
      "Saved best model checkpoint at epoch 31\n",
      "\n",
      "Start of epoch 32\n",
      "Step 0, Loss: 0.1644\n",
      "Step 35, Loss: 0.1499\n",
      "Training acc over epoch: 0.9913\n",
      "Validation acc: 0.4720\n",
      "Validation Loss: 0.4720\n",
      "Saved best model checkpoint at epoch 32\n",
      "\n",
      "Start of epoch 33\n",
      "Step 0, Loss: 0.1277\n",
      "Step 35, Loss: 0.1378\n",
      "Training acc over epoch: 0.9933\n",
      "Validation acc: 0.4704\n",
      "Validation Loss: 0.4704\n",
      "\n",
      "Start of epoch 34\n",
      "Step 0, Loss: 0.1002\n",
      "Step 35, Loss: 0.1091\n",
      "Training acc over epoch: 0.9946\n",
      "Validation acc: 0.4793\n",
      "Validation Loss: 0.4793\n",
      "Saved best model checkpoint at epoch 34\n",
      "\n",
      "Start of epoch 35\n",
      "Step 0, Loss: 0.1021\n",
      "Step 35, Loss: 0.1048\n",
      "Training acc over epoch: 0.9957\n",
      "Validation acc: 0.4886\n",
      "Validation Loss: 0.4886\n",
      "Saved best model checkpoint at epoch 35\n",
      "\n",
      "Start of epoch 36\n",
      "Step 0, Loss: 0.0833\n",
      "Step 35, Loss: 0.1043\n",
      "Training acc over epoch: 0.9978\n",
      "Validation acc: 0.4964\n",
      "Validation Loss: 0.4964\n",
      "Saved best model checkpoint at epoch 36\n",
      "\n",
      "Start of epoch 37\n",
      "Step 0, Loss: 0.0893\n",
      "Step 35, Loss: 0.0954\n",
      "Training acc over epoch: 0.9979\n",
      "Validation acc: 0.4917\n",
      "Validation Loss: 0.4917\n",
      "\n",
      "Start of epoch 38\n",
      "Step 0, Loss: 0.0743\n",
      "Step 35, Loss: 0.0827\n",
      "Training acc over epoch: 0.9980\n",
      "Validation acc: 0.4896\n",
      "Validation Loss: 0.4896\n",
      "\n",
      "Start of epoch 39\n",
      "Step 0, Loss: 0.0717\n",
      "Step 35, Loss: 0.0663\n",
      "Training acc over epoch: 0.9983\n",
      "Validation acc: 0.4979\n",
      "Validation Loss: 0.4979\n",
      "Saved best model checkpoint at epoch 39\n",
      "\n",
      "Start of epoch 40\n",
      "Step 0, Loss: 0.0645\n",
      "Step 35, Loss: 0.0612\n",
      "Training acc over epoch: 0.9987\n",
      "Validation acc: 0.4984\n",
      "Validation Loss: 0.4984\n",
      "Saved best model checkpoint at epoch 40\n",
      "\n",
      "Start of epoch 41\n",
      "Step 0, Loss: 0.0554\n",
      "Step 35, Loss: 0.0664\n",
      "Training acc over epoch: 0.9990\n",
      "Validation acc: 0.5021\n",
      "Validation Loss: 0.5021\n",
      "Saved best model checkpoint at epoch 41\n",
      "\n",
      "Start of epoch 42\n",
      "Step 0, Loss: 0.0485\n",
      "Step 35, Loss: 0.0563\n",
      "Training acc over epoch: 0.9990\n",
      "Validation acc: 0.5016\n",
      "Validation Loss: 0.5016\n",
      "\n",
      "Start of epoch 43\n",
      "Step 0, Loss: 0.0457\n",
      "Step 35, Loss: 0.0507\n",
      "Training acc over epoch: 0.9991\n",
      "Validation acc: 0.5016\n",
      "Validation Loss: 0.5016\n",
      "\n",
      "Start of epoch 44\n",
      "Step 0, Loss: 0.0483\n",
      "Step 35, Loss: 0.0513\n",
      "Training acc over epoch: 0.9992\n",
      "Validation acc: 0.5036\n",
      "Validation Loss: 0.5036\n",
      "Saved best model checkpoint at epoch 44\n",
      "\n",
      "Start of epoch 45\n",
      "Step 0, Loss: 0.0451\n",
      "Step 35, Loss: 0.0465\n",
      "Training acc over epoch: 0.9990\n",
      "Validation acc: 0.5026\n",
      "Validation Loss: 0.5026\n",
      "\n",
      "Start of epoch 46\n",
      "Step 0, Loss: 0.0379\n",
      "Step 35, Loss: 0.0386\n",
      "Training acc over epoch: 0.9994\n",
      "Validation acc: 0.5016\n",
      "Validation Loss: 0.5016\n",
      "\n",
      "Start of epoch 47\n",
      "Step 0, Loss: 0.0342\n",
      "Step 35, Loss: 0.0372\n",
      "Training acc over epoch: 0.9995\n",
      "Validation acc: 0.5036\n",
      "Validation Loss: 0.5036\n",
      "\n",
      "Start of epoch 48\n",
      "Step 0, Loss: 0.0380\n",
      "Step 35, Loss: 0.0349\n",
      "Training acc over epoch: 0.9995\n",
      "Validation acc: 0.4953\n",
      "Validation Loss: 0.4953\n",
      "\n",
      "Start of epoch 49\n",
      "Step 0, Loss: 0.0341\n",
      "Step 35, Loss: 0.0393\n",
      "Training acc over epoch: 0.9996\n",
      "Validation acc: 0.5124\n",
      "Validation Loss: 0.5124\n",
      "Saved best model checkpoint at epoch 49\n",
      "\n",
      "Start of epoch 50\n",
      "Step 0, Loss: 0.0306\n",
      "Step 35, Loss: 0.0407\n",
      "Training acc over epoch: 0.9997\n",
      "Validation acc: 0.5083\n",
      "Validation Loss: 0.5083\n",
      "\n",
      "Start of epoch 51\n",
      "Step 0, Loss: 0.0311\n",
      "Step 35, Loss: 0.0348\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5052\n",
      "Validation Loss: 0.5052\n",
      "\n",
      "Start of epoch 52\n",
      "Step 0, Loss: 0.0310\n",
      "Step 35, Loss: 0.0318\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5047\n",
      "Validation Loss: 0.5047\n",
      "\n",
      "Start of epoch 53\n",
      "Step 0, Loss: 0.0279\n",
      "Step 35, Loss: 0.0308\n",
      "Training acc over epoch: 0.9997\n",
      "Validation acc: 0.5135\n",
      "Validation Loss: 0.5135\n",
      "Saved best model checkpoint at epoch 53\n",
      "\n",
      "Start of epoch 54\n",
      "Step 0, Loss: 0.0302\n",
      "Step 35, Loss: 0.0255\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5145\n",
      "Validation Loss: 0.5145\n",
      "Saved best model checkpoint at epoch 54\n",
      "\n",
      "Start of epoch 55\n",
      "Step 0, Loss: 0.0281\n",
      "Step 35, Loss: 0.0254\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5073\n",
      "Validation Loss: 0.5073\n",
      "\n",
      "Start of epoch 56\n",
      "Step 0, Loss: 0.0290\n",
      "Step 35, Loss: 0.0296\n",
      "Training acc over epoch: 0.9994\n",
      "Validation acc: 0.5026\n",
      "Validation Loss: 0.5026\n",
      "\n",
      "Start of epoch 57\n",
      "Step 0, Loss: 0.0259\n",
      "Step 35, Loss: 0.0275\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5130\n",
      "Validation Loss: 0.5130\n",
      "\n",
      "Start of epoch 58\n",
      "Step 0, Loss: 0.0236\n",
      "Step 35, Loss: 0.0319\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5109\n",
      "Validation Loss: 0.5109\n",
      "\n",
      "Start of epoch 59\n",
      "Step 0, Loss: 0.0209\n",
      "Step 35, Loss: 0.0260\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5182\n",
      "Validation Loss: 0.5182\n",
      "Saved best model checkpoint at epoch 59\n",
      "\n",
      "Start of epoch 60\n",
      "Step 0, Loss: 0.0223\n",
      "Step 35, Loss: 0.0234\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5104\n",
      "Validation Loss: 0.5104\n",
      "\n",
      "Start of epoch 61\n",
      "Step 0, Loss: 0.0228\n",
      "Step 35, Loss: 0.0233\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5156\n",
      "Validation Loss: 0.5156\n",
      "\n",
      "Start of epoch 62\n",
      "Step 0, Loss: 0.0265\n",
      "Step 35, Loss: 0.0217\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5166\n",
      "Validation Loss: 0.5166\n",
      "\n",
      "Start of epoch 63\n",
      "Step 0, Loss: 0.0212\n",
      "Step 35, Loss: 0.0228\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5099\n",
      "Validation Loss: 0.5099\n",
      "\n",
      "Start of epoch 64\n",
      "Step 0, Loss: 0.0198\n",
      "Step 35, Loss: 0.0200\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5062\n",
      "Validation Loss: 0.5062\n",
      "\n",
      "Start of epoch 65\n",
      "Step 0, Loss: 0.0189\n",
      "Step 35, Loss: 0.0195\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5026\n",
      "Validation Loss: 0.5026\n",
      "\n",
      "Start of epoch 66\n",
      "Step 0, Loss: 0.0184\n",
      "Step 35, Loss: 0.0206\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5099\n",
      "Validation Loss: 0.5099\n",
      "\n",
      "Start of epoch 67\n",
      "Step 0, Loss: 0.0171\n",
      "Step 35, Loss: 0.0222\n",
      "Training acc over epoch: 0.9998\n",
      "Validation acc: 0.5150\n",
      "Validation Loss: 0.5150\n",
      "\n",
      "Start of epoch 68\n",
      "Step 0, Loss: 0.0223\n",
      "Step 35, Loss: 0.0181\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5150\n",
      "Validation Loss: 0.5150\n",
      "\n",
      "Start of epoch 69\n",
      "Step 0, Loss: 0.0158\n",
      "Step 35, Loss: 0.0184\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5171\n",
      "Validation Loss: 0.5171\n",
      "\n",
      "Start of epoch 70\n",
      "Step 0, Loss: 0.0183\n",
      "Step 35, Loss: 0.0172\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5104\n",
      "Validation Loss: 0.5104\n",
      "\n",
      "Start of epoch 71\n",
      "Step 0, Loss: 0.0157\n",
      "Step 35, Loss: 0.0168\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5140\n",
      "Validation Loss: 0.5140\n",
      "\n",
      "Start of epoch 72\n",
      "Step 0, Loss: 0.0167\n",
      "Step 35, Loss: 0.0167\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5182\n",
      "Validation Loss: 0.5182\n",
      "\n",
      "Start of epoch 73\n",
      "Step 0, Loss: 0.0198\n",
      "Step 35, Loss: 0.0173\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5135\n",
      "Validation Loss: 0.5135\n",
      "\n",
      "Start of epoch 74\n",
      "Step 0, Loss: 0.0144\n",
      "Step 35, Loss: 0.0169\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5099\n",
      "Validation Loss: 0.5099\n",
      "\n",
      "Start of epoch 75\n",
      "Step 0, Loss: 0.0143\n",
      "Step 35, Loss: 0.0157\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5135\n",
      "Validation Loss: 0.5135\n",
      "\n",
      "Start of epoch 76\n",
      "Step 0, Loss: 0.0150\n",
      "Step 35, Loss: 0.0161\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5145\n",
      "Validation Loss: 0.5145\n",
      "\n",
      "Start of epoch 77\n",
      "Step 0, Loss: 0.0149\n",
      "Step 35, Loss: 0.0157\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5166\n",
      "Validation Loss: 0.5166\n",
      "\n",
      "Start of epoch 78\n",
      "Step 0, Loss: 0.0135\n",
      "Step 35, Loss: 0.0140\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5166\n",
      "Validation Loss: 0.5166\n",
      "\n",
      "Start of epoch 79\n",
      "Step 0, Loss: 0.0122\n",
      "Step 35, Loss: 0.0168\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5140\n",
      "Validation Loss: 0.5140\n",
      "\n",
      "Start of epoch 80\n",
      "Step 0, Loss: 0.0120\n",
      "Step 35, Loss: 0.0135\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5171\n",
      "Validation Loss: 0.5171\n",
      "\n",
      "Start of epoch 81\n",
      "Step 0, Loss: 0.0128\n",
      "Step 35, Loss: 0.0132\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5161\n",
      "Validation Loss: 0.5161\n",
      "\n",
      "Start of epoch 82\n",
      "Step 0, Loss: 0.0133\n",
      "Step 35, Loss: 0.0132\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5130\n",
      "Validation Loss: 0.5130\n",
      "\n",
      "Start of epoch 83\n",
      "Step 0, Loss: 0.0127\n",
      "Step 35, Loss: 0.0141\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5156\n",
      "Validation Loss: 0.5156\n",
      "\n",
      "Start of epoch 84\n",
      "Step 0, Loss: 0.0159\n",
      "Step 35, Loss: 0.0129\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5124\n",
      "Validation Loss: 0.5124\n",
      "\n",
      "Start of epoch 85\n",
      "Step 0, Loss: 0.0118\n",
      "Step 35, Loss: 0.0126\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5109\n",
      "Validation Loss: 0.5109\n",
      "\n",
      "Start of epoch 86\n",
      "Step 0, Loss: 0.0119\n",
      "Step 35, Loss: 0.0126\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5156\n",
      "Validation Loss: 0.5156\n",
      "\n",
      "Start of epoch 87\n",
      "Step 0, Loss: 0.0132\n",
      "Step 35, Loss: 0.0112\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5176\n",
      "Validation Loss: 0.5176\n",
      "\n",
      "Start of epoch 88\n",
      "Step 0, Loss: 0.0121\n",
      "Step 35, Loss: 0.0131\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5130\n",
      "Validation Loss: 0.5130\n",
      "\n",
      "Start of epoch 89\n",
      "Step 0, Loss: 0.0108\n",
      "Step 35, Loss: 0.0109\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5114\n",
      "Validation Loss: 0.5114\n",
      "\n",
      "Start of epoch 90\n",
      "Step 0, Loss: 0.0115\n",
      "Step 35, Loss: 0.0120\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5093\n",
      "Validation Loss: 0.5093\n",
      "\n",
      "Start of epoch 91\n",
      "Step 0, Loss: 0.0117\n",
      "Step 35, Loss: 0.0117\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5145\n",
      "Validation Loss: 0.5145\n",
      "\n",
      "Start of epoch 92\n",
      "Step 0, Loss: 0.0101\n",
      "Step 35, Loss: 0.0116\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5119\n",
      "Validation Loss: 0.5119\n",
      "\n",
      "Start of epoch 93\n",
      "Step 0, Loss: 0.0115\n",
      "Step 35, Loss: 0.0105\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5156\n",
      "Validation Loss: 0.5156\n",
      "\n",
      "Start of epoch 94\n",
      "Step 0, Loss: 0.0107\n",
      "Step 35, Loss: 0.0113\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5099\n",
      "Validation Loss: 0.5099\n",
      "\n",
      "Start of epoch 95\n",
      "Step 0, Loss: 0.0107\n",
      "Step 35, Loss: 0.0104\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5099\n",
      "Validation Loss: 0.5099\n",
      "\n",
      "Start of epoch 96\n",
      "Step 0, Loss: 0.0095\n",
      "Step 35, Loss: 0.0108\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5176\n",
      "Validation Loss: 0.5176\n",
      "\n",
      "Start of epoch 97\n",
      "Step 0, Loss: 0.0099\n",
      "Step 35, Loss: 0.0098\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5130\n",
      "Validation Loss: 0.5130\n",
      "\n",
      "Start of epoch 98\n",
      "Step 0, Loss: 0.0105\n",
      "Step 35, Loss: 0.0103\n",
      "Training acc over epoch: 1.0000\n",
      "Validation acc: 0.5156\n",
      "Validation Loss: 0.5156\n",
      "\n",
      "Start of epoch 99\n",
      "Step 0, Loss: 0.0098\n",
      "Step 35, Loss: 0.0092\n",
      "Training acc over epoch: 0.9999\n",
      "Validation acc: 0.5150\n",
      "Validation Loss: 0.5150\n",
      "total train time 108.6821961402893\n",
      "Loading best model weights...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x19c80c8e788>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# 前向傳播與梯度計算函數 (訓練步驟)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss = loss_fn(y, logits)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def val_step(x, y):\n",
    "    val_predictions = model(x, training=False)\n",
    "    loss = loss_fn(y, val_predictions)\n",
    "    val_acc_metric.update_state(y, val_predictions)\n",
    "    return loss\n",
    "# 訓練循環\n",
    "# 添加必要的導入\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# 設置checkpoint路徑\n",
    "checkpoint_path = \"training_checkpoints/conv4_meta_affine/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# ... train_step 和 val_step 函數保持不變 ...\n",
    "\n",
    "# 訓練循環\n",
    "epochs = 100\n",
    "total = 0\n",
    "# best_val_loss = float('inf')\n",
    "best_val_loss = 0\n",
    "patience = 90  # early stopping 耐心值\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nStart of epoch {epoch}\")\n",
    "    \n",
    "    # 訓練每個批次\n",
    "    learning_rate = learning_rate/(1+alpha * epoch)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(omni_train):\n",
    "        loss = train_step(x_batch_train, y_batch_train)\n",
    "        if step % 35 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.numpy():.4f}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total += (end_time-start_time)\n",
    "    \n",
    "    # 驗證階段\n",
    "    val_losses = []\n",
    "    for x_batch_val, y_batch_val in omni_val:\n",
    "        val_loss = val_step(x_batch_val, y_batch_val)\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    # 計算平均驗證損失\n",
    "    # current_val_loss = tf.reduce_mean(val_losses)\n",
    "     \n",
    "    # 顯示訓練與驗證的準確率\n",
    "    train_acc = train_acc_metric.result()\n",
    "    val_acc = val_acc_metric.result()\n",
    "    current_val_loss = val_acc\n",
    "    print(f\"Training acc over epoch: {train_acc:.4f}\")\n",
    "    print(f\"Validation acc: {val_acc:.4f}\")\n",
    "    print(f\"Validation Loss: {current_val_loss:.4f}\")\n",
    "    \n",
    "    # 檢查並保存最佳模型\n",
    "    if current_val_loss > best_val_loss:\n",
    "        best_val_loss = current_val_loss\n",
    "        # 確保checkpoint目錄存在\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        # 保存模型權重\n",
    "        model.save_weights(checkpoint_path.format(epoch=epoch))\n",
    "        print(f\"Saved best model checkpoint at epoch {epoch}\")\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    # 重置訓練和驗證指標\n",
    "    train_acc_metric.reset_states()\n",
    "    val_acc_metric.reset_states()\n",
    "\n",
    "print(\"total train time\", total)\n",
    "\n",
    "# 訓練結束後載入最佳模型\n",
    "print(\"Loading best model weights...\")\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取feature extractor網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_without_dense_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           multiple                  640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              multiple                  0 (unused)\n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           multiple                  36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           multiple                  36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           multiple                  36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc multiple                  256       \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 112,448\n",
      "Trainable params: 111,936\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tempw = model.get_weights()\n",
    "tempw = tempw[:-2]\n",
    "# 移除最後一層並重新構建新的模型\n",
    "class MyModelWithoutDense(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModelWithoutDense, self).__init__()\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.bn1   = tf.keras.layers.BatchNormalization()\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.bn2   = tf.keras.layers.BatchNormalization()\n",
    "        self.relu2 = tf.keras.layers.ReLU()\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.bn3   = tf.keras.layers.BatchNormalization()\n",
    "        self.relu3 = tf.keras.layers.ReLU()\n",
    "        self.pool3 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")\n",
    "        self.bn4   = tf.keras.layers.BatchNormalization()\n",
    "        self.relu4 = tf.keras.layers.ReLU()\n",
    "        self.pool4 = tf.keras.layers.MaxPool2D()\n",
    "        \n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "\n",
    "    def call(self, input, training=False):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.flat(x)\n",
    "\n",
    "        return x  # 注意沒有 dense 層了\n",
    "\n",
    "# 創建新的模型\n",
    "train_model = MyModelWithoutDense()\n",
    "\n",
    "# 載入之前訓練的權重\n",
    "train_model.build(input_shape=(None, 28, 28, 1))  # 確保模型結構正確\n",
    "train_model.set_weights(tempw)\n",
    "\n",
    "# 顯示新的模型結構\n",
    "train_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "omni fewshot test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回合 100, 最近100次的平均準確率: 0.9431999999999996\n",
      "回合 200, 最近100次的平均準確率: 0.9473333333333332\n",
      "回合 300, 最近100次的平均準確率: 0.9501333333333329\n",
      "回合 400, 最近100次的平均準確率: 0.9503999999999995\n",
      "回合 500, 最近100次的平均準確率: 0.9481333333333332\n",
      "回合 600, 最近100次的平均準確率: 0.9465333333333331\n",
      "回合 700, 最近100次的平均準確率: 0.9509333333333332\n",
      "回合 800, 最近100次的平均準確率: 0.9450666666666666\n",
      "回合 900, 最近100次的平均準確率: 0.9497333333333333\n",
      "回合 1000, 最近100次的平均準確率: 0.9481333333333332\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均準確率: 0.947960000000005\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... existing code for function definitions ...\n",
    "def compute_prototypes(trained_model, support_set, n_way, k_shot):\n",
    "    prototypes = []\n",
    "    for i in range(n_way):\n",
    "        support_samples = support_set[i * k_shot:(i + 1) * k_shot]\n",
    "        features = trained_model(support_samples)  # 提取支持樣本的特徵\n",
    "        class_prototype = tf.reduce_mean(features, axis=0)  # 計算特徵均值\n",
    "        prototypes.append(class_prototype)\n",
    "    return tf.stack(prototypes)\n",
    "\n",
    "# 余弦相似度計算\n",
    "def cosine_similarity(a, b):\n",
    "    a = tf.nn.l2_normalize(a, axis=-1)\n",
    "    b = tf.nn.l2_normalize(b, axis=-1)\n",
    "    return tf.reduce_sum(a * b, axis=-1)\n",
    "\n",
    "# 對查詢樣本進行分類\n",
    "def classify_query_samples(trained_model, query_set, prototypes):\n",
    "    query_features = trained_model(query_set)  # 提取查詢樣本的特徵\n",
    "    similarities = [cosine_similarity(query_features, proto) for proto in prototypes]\n",
    "    similarities = tf.stack(similarities, axis=-1)\n",
    "    predicted_labels = tf.argmax(similarities, axis=-1)  # 根據相似度最大選擇類別\n",
    "    return predicted_labels\n",
    "\n",
    "# 模型參數\n",
    "n_way = 5  # 20個類別\n",
    "k_shot = 5  # 每個類別5個支持樣本\n",
    "numbers = list(range(964, 1623))  # 類別編號\n",
    "\n",
    "# 預先生成1000組固定的測試樣本\n",
    "random.seed(42)  # 設定隨機種子以確保可重複性\n",
    "fixed_samples = []\n",
    "for _ in range(1000):\n",
    "    label_subset = random.choices(numbers, k=n_way)\n",
    "    fixed_samples.append(label_subset)\n",
    "\n",
    "def run_evaluation():\n",
    "    acc = []  # 紀錄每次準確率\n",
    "    avg_acc_per_100 = []  # 每100次的平均準確率\n",
    "    \n",
    "    # 開始計算\n",
    "    for clk in range(1000):\n",
    "        text = 0\n",
    "        label_subset = fixed_samples[clk]  # 使用預先生成的樣本\n",
    "        support_set = []\n",
    "        query_set = []\n",
    "\n",
    "        # 構造支持集和查詢集\n",
    "        for class_idx in label_subset:\n",
    "            support_set.extend(x_omni_test[(class_idx - 964) * 20:(class_idx - 964) * 20 + k_shot])\n",
    "            text += 1\n",
    "\n",
    "        text = 0\n",
    "        for class_idx in label_subset:\n",
    "            query_set.extend(x_omni_test[(class_idx - 964) * 20 + k_shot:(class_idx - 964) * 20 + 20])\n",
    "            text += 3\n",
    "\n",
    "        # 轉換為張量\n",
    "        sup_tensor = tf.convert_to_tensor(support_set)\n",
    "        que_tensor = tf.convert_to_tensor(query_set)\n",
    "        \n",
    "        # 計算類原型\n",
    "        prototypes = compute_prototypes(train_model, sup_tensor, n_way, k_shot)\n",
    "\n",
    "        # 對查詢樣本進行分類\n",
    "        predicted_labels = classify_query_samples(train_model, que_tensor, prototypes)\n",
    "\n",
    "        # 計算準確率\n",
    "        count = 0\n",
    "        t = 0\n",
    "        k = 0\n",
    "        for i in range(n_way):\n",
    "            for j in range(20 - k_shot):\n",
    "                if predicted_labels[t + j] == k:\n",
    "                    count += 1\n",
    "            t += 20 - k_shot\n",
    "            k += 1\n",
    "\n",
    "        acc.append((count / (n_way * (20 - k_shot))))\n",
    "\n",
    "        # 每100次記錄平均值\n",
    "        if (clk + 1) % 100 == 0:\n",
    "            avg_acc = sum(acc[-100:]) / 100\n",
    "            avg_acc_per_100.append(avg_acc)\n",
    "            print(f\"回合 {clk + 1}, 最近100次的平均準確率: {avg_acc}\")\n",
    "\n",
    "    return acc, avg_acc_per_100\n",
    "\n",
    "# 執行評估\n",
    "acc, avg_acc_per_100 = run_evaluation()\n",
    "\n",
    "# 繪製圖表\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "# 原始 x 和 y 數據\n",
    "x = np.arange(1, len(avg_acc_per_100) + 1)\n",
    "y = np.array(avg_acc_per_100)\n",
    "\n",
    "# 插值處理\n",
    "x_new = np.linspace(x.min(), x.max(), 300)\n",
    "spl = make_interp_spline(x, y, k=3)\n",
    "y_smooth = spl(x_new)\n",
    "\n",
    "# 繪圖\n",
    "plt.plot(x_new, y_smooth, label=\"smoothed avg accuracy\")\n",
    "plt.xlabel(\"every 100 times\")\n",
    "plt.ylabel(\"avg accuracy\")\n",
    "plt.title(\"test result\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "avg_acc = sum(acc[:]) / 1000\n",
    "print(f\"平均準確率: {avg_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UMTRA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
